{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the DCGAN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator and Generator heads builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcgan_heads_builder(input_shape, coef_latent = 4, show_summary = True):\n",
    "    \"\"\"Build a simple DCGAN model for low resolution image\n",
    "     generation tasks\"\"\"\n",
    "    def build_discriminator(input_shape, show_summary = True):\n",
    "        \"\"\"Builds the discriminator head, which downsamples the input and\n",
    "           will be us used to classify fake/true data\"\"\"\n",
    "        base_channels =  input_shape[0]\n",
    "        latent_dim = base_channels * 2\n",
    "        discriminator = keras.Sequential([\n",
    "            layers.Input(shape=input_shape),\n",
    "            layers.Conv2D(base_channels, kernel_size=4, strides=2, padding=\"same\"),\n",
    "            layers.LeakyReLU(negative_slope=0.2),\n",
    "            layers.Conv2D(base_channels * 2, kernel_size=4, strides=2, padding=\"same\"),\n",
    "            layers.LeakyReLU(negative_slope=0.2),\n",
    "            layers.Conv2D(base_channels * 2, kernel_size=4, strides=2, padding=\"same\"),\n",
    "            layers.LeakyReLU(negative_slope=0.2),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(1, activation=\"sigmoid\")\n",
    "        ], name=\"discriminator\")\n",
    "\n",
    "        if show_summary:\n",
    "            discriminator.summary()\n",
    "\n",
    "        return discriminator, latent_dim\n",
    "    \n",
    "    def build_generator(latent_dim, coef_latent, show_summary = True):\n",
    "        \"\"\"Builds the generator head which will accept random noise(shape = latent_dim * coef_latent^2 dimensionality)\n",
    "           and upscale it to a new synthetic image\n",
    "           \n",
    "           Feel free to adjust the coefficient according to your datasets needs. For example, \n",
    "           4 * 4 will generate images of (32,32,3) shape.\n",
    "\n",
    "           \"\"\"\n",
    "        generator = keras.Sequential([\n",
    "            keras.Input(shape=(latent_dim,)),\n",
    "            layers.Dense(coef_latent * coef_latent * latent_dim),\n",
    "            layers.Reshape((coef_latent, coef_latent, latent_dim)),\n",
    "            layers.Conv2DTranspose(latent_dim, kernel_size=4, strides=2, padding=\"same\"),\n",
    "            layers.LeakyReLU(negative_slope=0.2),\n",
    "            layers.Conv2DTranspose(latent_dim * 2, kernel_size=4, strides=2, padding=\"same\"),\n",
    "            layers.LeakyReLU(negative_slope=0.2),\n",
    "            layers.Conv2DTranspose(latent_dim * 4, kernel_size=4, strides=2, padding=\"same\"),\n",
    "            layers.LeakyReLU(negative_slope=0.2),\n",
    "            layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\")],\n",
    "            name=\"generator\")\n",
    "        \n",
    "        if show_summary:\n",
    "            generator.summary()\n",
    "\n",
    "        return generator\n",
    "    \n",
    "    # Create the two heads as Keras sequential models\n",
    "    discriminator, latent_dim = build_discriminator(input_shape, show_summary = show_summary)\n",
    "    generator = build_generator(latent_dim, coef_latent=coef_latent, show_summary = show_summary)\n",
    "\n",
    "    return generator, discriminator, latent_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DCGAN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"DCGAN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ discriminator (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">101,025</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ generator (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)          │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">807,107</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ discriminator (\u001b[38;5;33mSequential\u001b[0m)      │ ?                      │       \u001b[38;5;34m101,025\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ generator (\u001b[38;5;33mSequential\u001b[0m)          │ ?                      │       \u001b[38;5;34m807,107\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">908,132</span> (3.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m908,132\u001b[0m (3.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">908,132</span> (3.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m908,132\u001b[0m (3.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "class DCGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed_generator = tf.random.Generator.from_seed(1337)\n",
    "        self.name = 'DCGAN'\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = self.seed_generator.normal(\n",
    "            shape=(batch_size, self.latent_dim)\n",
    "        )\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Create labels for generated and fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Force the discriminator to struggle by adding some random noise\n",
    "        # to the labels.\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = self.seed_generator.normal(\n",
    "            shape=(batch_size, self.latent_dim)\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "IMAGE_SHAPE = (32,32,3)\n",
    "generator, discriminator, latent_dim = dcgan_heads_builder(IMAGE_SHAPE, show_summary= False)\n",
    "model = DCGAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "model.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True)\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
